# app.py
import streamlit as st
import os
from supabase import create_client
from datetime import datetime
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# =========================
# Supabase æ¥ç¶š
# =========================
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_ANON_KEY")
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

# =========================
# Streamlit UI è¨­å®š
# =========================
st.set_page_config(page_title="Language Learning Chat", layout="wide")
st.title("ğŸŒ Language Learning Chat")

# =========================
# st.session_state åˆæœŸåŒ–
# =========================
for key, default in [
    ("user_id", None), 
    ("display_name", None), 
    ("messages", []), 
    ("model_loaded", False),
    ("selected_room", None),
    ("show_translation", True)
]:
    if key not in st.session_state:
        st.session_state[key] = default

# =========================
# ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™»éŒ² / ãƒ­ã‚°ã‚¤ãƒ³
# =========================
with st.sidebar:
    st.header("ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±")
    email = st.text_input("ãƒ¡ãƒ¼ãƒ«")
    display_name = st.text_input("è¡¨ç¤ºå")
    mother_tongue = st.selectbox("æ¯èª", ["Japanese", "English", "Maori"])
    
    if st.button("ãƒ­ã‚°ã‚¤ãƒ³ / ç™»éŒ²"):
        resp = supabase.table("users").select("*").eq("email", email).execute()
        if resp.data:
            user = resp.data[0]
        else:
            user = supabase.table("users").insert({
                "email": email,
                "display_name": display_name,
                "mother_tongue": mother_tongue
            }).execute().data[0]
        st.session_state.user_id = user["id"]
        st.session_state.display_name = user["display_name"]
        st.success(f"ãƒ­ã‚°ã‚¤ãƒ³ã—ã¾ã—ãŸ: {user['display_name']}")

# =========================
# ãƒ«ãƒ¼ãƒ é¸æŠ / ä½œæˆ
# =========================
if st.session_state.user_id:
    st.header("å­¦ç¿’ãƒ«ãƒ¼ãƒ ")

    # ãƒ«ãƒ¼ãƒ ä¸€è¦§ã‚’å–å¾—
    rooms_resp = supabase.table("rooms").select("*").execute()
    rooms = rooms_resp.data
    room_names = [r["name"] for r in rooms] if rooms else []

    selected_room_name = st.selectbox("æ—¢å­˜ãƒ«ãƒ¼ãƒ é¸æŠ", room_names) if room_names else ""
    create_new = st.text_input("æ–°ã—ã„ãƒ«ãƒ¼ãƒ ã‚’ä½œã‚‹å ´åˆã¯åå‰ã‚’å…¥åŠ›")

    if st.button("ãƒ«ãƒ¼ãƒ ä½œæˆ"):
        if create_new:
            room = supabase.table("rooms").insert({
                "owner_user_id": st.session_state.user_id,
                "name": create_new,
                "language": "English"
            }).execute().data[0]
            st.success(f"ãƒ«ãƒ¼ãƒ ä½œæˆ: {room['name']}")
            st.session_state.selected_room = room
        else:
            st.warning("ãƒ«ãƒ¼ãƒ åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

    # é¸æŠã•ã‚ŒãŸãƒ«ãƒ¼ãƒ æƒ…å ±
    if not st.session_state.selected_room and selected_room_name:
        st.session_state.selected_room = next((r for r in rooms if r["name"] == selected_room_name), None)

# =========================
# ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½
# =========================
if st.session_state.selected_room:
    room = st.session_state.selected_room
    st.subheader(f"Room: {room['name']} ({room['language']})")

    # æ¯èªç¿»è¨³è¡¨ç¤º
    st.session_state.show_translation = st.checkbox("æ¯èªç¿»è¨³ã‚’è¡¨ç¤º", value=st.session_state.show_translation)

    # ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ï¼ˆè»½é‡ç‰ˆï¼‰
    @st.cache_resource
    def load_model():
        tokenizer = AutoTokenizer.from_pretrained("microsoft/DialoGPT-small")
        model = AutoModelForCausalLM.from_pretrained("microsoft/DialoGPT-small")
        model.eval()
        return tokenizer, model

    if not st.session_state.model_loaded:
        st.session_state.tokenizer, st.session_state.model = load_model()
        st.session_state.model_loaded = True

    tokenizer = st.session_state.tokenizer
    model = st.session_state.model

    # å…¥åŠ›
    user_input = st.text_input("ã‚ãªãŸã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:", key="input_msg")
    if st.button("é€ä¿¡") and user_input:
        # DBä¿å­˜
        supabase.table("messages").insert({
            "room_id": room["id"],
            "user_id": st.session_state.user_id,
            "role": "user",
            "content": user_input,
            "created_at": datetime.utcnow().isoformat()
        }).execute()

        # AIå¿œç­”ç”Ÿæˆ
        inputs = tokenizer.encode(user_input + tokenizer.eos_token, return_tensors="pt")
        outputs = model.generate(inputs, max_length=100, pad_token_id=tokenizer.eos_token_id)
        bot_response = tokenizer.decode(outputs[:, inputs.shape[-1]:][0], skip_special_tokens=True)

        # DBä¿å­˜
        supabase.table("messages").insert({
            "room_id": room["id"],
            "role": "bot",
            "content": bot_response,
            "created_at": datetime.utcnow().isoformat()
        }).execute()

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
        st.session_state.messages.append({"role": "user", "content": user_input})
        st.session_state.messages.append({"role": "bot", "content": bot_response})

    # éå»ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤º
    for msg in st.session_state.messages:
        if msg["role"] == "user":
            st.markdown(f"**ã‚ãªãŸ:** {msg['content']}")
        else:
            text = msg["content"]
            if st.session_state.show_translation:
                words = text.split()
                translated_words = []
                for w in words:
                    resp = supabase.table("vocab")\
                        .select("target_word")\
                        .eq("source_word", w)\
                        .eq("language", room["language"])\
                        .execute()
                    if resp.data:
                        translated_words.append(resp.data[0]["target_word"])
                    else:
                        translated_words.append(w)
                text += " _(æ¯èªè¨³: " + " ".join(translated_words) + ")_"
            st.markdown(f"**AI:** {text}")

    # å˜èªå¸³è¿½åŠ 
    st.subheader("å˜èªå¸³ã«è¿½åŠ ")
    new_word = st.text_input("è¿½åŠ ã—ãŸã„å˜èªã‚’å…¥åŠ›", key="vocab_input")
    if st.button("å˜èªã‚’ä¿å­˜", key="save_vocab"):
        exists = supabase.table("vocab")\
            .select("*")\
            .eq("user_id", st.session_state.user_id)\
            .eq("source_word", new_word)\
            .eq("language", room["language"])\
            .execute()
        if not exists.data:
            supabase.table("vocab").insert({
                "user_id": st.session_state.user_id,
                "source_word": new_word,
                "target_word": "",
                "language": room["language"]
            }).execute()
            st.success(f"{new_word} ã‚’å˜èªå¸³ã«è¿½åŠ ã—ã¾ã—ãŸ")

    # å˜èªå¸³è¡¨ç¤º
    st.subheader("å˜èªå¸³ï¼ˆå¾©ç¿’ç”¨ï¼‰")
    vocab_list = supabase.table("vocab")\
        .select("*")\
        .eq("user_id", st.session_state.user_id)\
        .eq("language", room["language"])\
        .execute()
    for v in vocab_list.data:
        st.markdown(f"- {v['source_word']} â†’ {v.get('target_word', '')}")

else:
    if st.session_state.user_id:
        st.warning("ãƒ«ãƒ¼ãƒ ã‚’ä½œæˆã¾ãŸã¯é¸æŠã—ã¦ãã ã•ã„ã€‚")
